import asyncio
from typing import TypedDict
from pathlib import Path
from langgraph.graph import StateGraph, END
from src.ai.agents.analyzer import RepositoryAnalysisAgent
from src.ai.agents.task_breaker import TaskBreakdownAgent
from src.repository.cloner import RepositoryCloner
from src.repository.analyzer import RepositoryAnalyzer
from src.github.client import GitHubClient
from src.github.mutations import CREATE_ISSUE, ADD_TO_PROJECT
from src.config import settings
from src.utils.logger import get_logger

logger = get_logger(__name__)


class WorkflowState(TypedDict):
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çŠ¶æ…‹"""

    task_description: str
    repo_url: str
    repo_path: Path | None
    is_implemented: bool
    confidence: float
    subtasks: list
    created_issues: list
    error: str


class CreateTaskWorkflow:
    """ã‚¿ã‚¹ã‚¯ä½œæˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""

    def __init__(self):
        self.cloner = RepositoryCloner()
        self.analyzer_agent = RepositoryAnalysisAgent()
        self.breakdown_agent = TaskBreakdownAgent()
        self.workflow = self._build_workflow()

    def _build_workflow(self) -> StateGraph:
        """LangGraphãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰"""

        workflow = StateGraph(WorkflowState)

        # ãƒãƒ¼ãƒ‰è¿½åŠ 
        workflow.add_node("clone_repo", self._clone_repo)
        workflow.add_node("analyze_implementation", self._analyze_implementation)
        workflow.add_node("breakdown_task", self._breakdown_task)
        workflow.add_node("create_issues", self._create_issues)

        # ã‚¨ãƒƒã‚¸è¿½åŠ 
        workflow.set_entry_point("clone_repo")
        workflow.add_edge("clone_repo", "analyze_implementation")
        workflow.add_conditional_edges(
            "analyze_implementation",
            self._should_create_tasks,
            {"create": "breakdown_task", "skip": END},
        )
        workflow.add_edge("breakdown_task", "create_issues")
        workflow.add_edge("create_issues", END)

        return workflow.compile()

    async def _clone_repo(self, state: WorkflowState) -> WorkflowState:
        """ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³"""
        try:
            logger.info(f"Cloning repository: {state['repo_url']}")
            repo_path = await self.cloner.clone_or_update(state["repo_url"])
            state["repo_path"] = repo_path
            logger.info(f"Repository cloned to: {repo_path}")
        except Exception as e:
            state["error"] = f"Clone failed: {str(e)}"
            logger.error(state["error"], exc_info=True)

        return state

    async def _analyze_implementation(self, state: WorkflowState) -> WorkflowState:
        """å®Ÿè£…çŠ¶æ³ã‚’åˆ†æ"""
        try:
            logger.info("Analyzing implementation status")
            analysis = await self.analyzer_agent.analyze_implementation_status(
                state["repo_path"], state["task_description"]
            )

            state["is_implemented"] = analysis["is_implemented"]
            state["confidence"] = analysis["confidence"]

            logger.info(
                f"Analysis complete: implemented={state['is_implemented']}, "
                f"confidence={state['confidence']}"
            )
        except Exception as e:
            state["error"] = f"Analysis failed: {str(e)}"
            logger.error(state["error"], exc_info=True)

        return state

    def _should_create_tasks(self, state: WorkflowState) -> str:
        """ã‚¿ã‚¹ã‚¯ä½œæˆãŒå¿…è¦ã‹åˆ¤å®š"""
        if state.get("error"):
            return "skip"

        # å®Ÿè£…æ¸ˆã¿ã¾ãŸã¯é«˜ä¿¡é ¼åº¦ã§å®Ÿè£…æ¸ˆã¿ã¨åˆ¤å®š
        if state["is_implemented"] and state["confidence"] > 0.7:
            logger.info("Task already implemented, skipping creation")
            return "skip"

        return "create"

    async def _breakdown_task(self, state: WorkflowState) -> WorkflowState:
        """ã‚¿ã‚¹ã‚¯ã‚’åˆ†è§£"""
        try:
            logger.info("=" * 80)
            logger.info("ğŸš€ [ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼] ã‚¿ã‚¹ã‚¯åˆ†è§£ãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹")
            logger.info("=" * 80)
            logger.info(f"ğŸ“ ã‚¿ã‚¹ã‚¯: {state['task_description']}")

            # ãƒªãƒã‚¸ãƒˆãƒªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
            analyzer = RepositoryAnalyzer(state["repo_path"])
            file_tree = analyzer.get_file_tree()
            summary = analyzer.get_project_summary()

            logger.info("\n" + "â”€" * 80)
            logger.info("ğŸ“ [ãƒ•ã‚§ãƒ¼ã‚º 1/3] ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º")
            logger.info("â”€" * 80)

            # ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
            keywords = await self.breakdown_agent.extract_keywords(
                state["task_description"]
            )

            logger.info("\n" + "â”€" * 80)
            logger.info("ğŸ“ [ãƒ•ã‚§ãƒ¼ã‚º 2/3] ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æ")
            logger.info("â”€" * 80)

            # è³¢ãã‚³ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã‚€ï¼ˆtree-sitter + ripgrepï¼‰
            code_content = analyzer.read_code_intelligently(
                keywords, max_functions=20, max_chars=50000
            )

            logger.info("\n" + "â”€" * 80)
            logger.info("ğŸ“ [ãƒ•ã‚§ãƒ¼ã‚º 3/3] ã‚¿ã‚¹ã‚¯åˆ†è§£å®Ÿè¡Œ")
            logger.info("â”€" * 80)

            repo_context = f"""
# Project Structure
{file_tree}

# Project Summary
{summary}

# Related Code
{code_content if code_content else "No relevant code files found."}
"""

            subtasks = await self.breakdown_agent.break_down(
                state["task_description"], repo_context
            )

            state["subtasks"] = subtasks

            logger.info("\n" + "=" * 80)
            logger.info(f"âœ… [ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼] ã‚¿ã‚¹ã‚¯åˆ†è§£å®Œäº†: {len(subtasks)} å€‹ã®ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆ")
            logger.info("=" * 80)

        except Exception as e:
            state["error"] = f"Breakdown failed: {str(e)}"
            logger.error(state["error"], exc_info=True)

        return state

    async def _create_issues(self, state: WorkflowState) -> WorkflowState:
        """GitHub Issuesã‚’ä½œæˆ"""
        try:
            logger.info("\n" + "=" * 80)
            logger.info("ğŸ“ [ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼] GitHub Issuesä½œæˆãƒ•ã‚§ãƒ¼ã‚ºé–‹å§‹")
            logger.info("=" * 80)
            logger.info(f"ğŸ¯ ä½œæˆäºˆå®š: {len(state['subtasks'])} å€‹ã®Issue")
            github = GitHubClient()
            created_issues = []

            # Repository IDã€Project IDã€ãŠã‚ˆã³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æƒ…å ±ã‚’å–å¾—
            from src.github.queries import (
                GET_REPOSITORY_AND_PROJECT_IDS,
                GET_PROJECT_FIELDS,
            )

            ids_result = await github.execute_query(
                GET_REPOSITORY_AND_PROJECT_IDS,
                {
                    "org": settings.GITHUB_ORG,
                    "repo": settings.GITHUB_REPO,
                    "projectNumber": settings.GITHUB_PROJECT_NUMBER,
                },
            )

            repo_id = ids_result["repository"]["id"]
            project_id = ids_result["user"]["projectV2"]["id"]

            # Sizeãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æƒ…å ±ã‚’å–å¾—
            fields_result = await github.execute_query(
                GET_PROJECT_FIELDS,
                {
                    "org": settings.GITHUB_ORG,
                    "projectNumber": settings.GITHUB_PROJECT_NUMBER,
                },
            )

            # Sizeãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¢ã™
            size_field = None
            for field in fields_result["user"]["projectV2"]["fields"]["nodes"]:
                if field.get("name") == "Size":
                    size_field = field
                    break

            if not size_field:
                logger.warning("Size field not found in project")

            # å„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’IssueåŒ–
            logger.info("\n" + "â”€" * 80)
            logger.info("ğŸ”§ å„ã‚µãƒ–ã‚¿ã‚¹ã‚¯ã‚’IssueåŒ–")
            logger.info("â”€" * 80)

            for i, subtask in enumerate(state["subtasks"], 1):
                logger.info(f"\nğŸ“Œ [{i}/{len(state['subtasks'])}] {subtask['title']}")
                # å‚è€ƒã‚³ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰
                reference_section = ""
                if subtask.get("reference_code"):
                    ref = subtask["reference_code"]
                    reference_section = f"""

## Reference Code
**File**: `{ref.get("file_path", "")}`

```python
{ref.get("snippet", "")}
```

**Note**: {ref.get("explanation", "")}
"""

                # Issueä½œæˆ
                issue_body = f"""
## Description
{subtask["description"]}

## Acceptance Criteria
{chr(10).join(f"- [ ] {criterion}" for criterion in subtask.get("acceptance_criteria", []))}

## Estimated Effort
{subtask.get("estimated_effort", "M")}

## Dependencies
{chr(10).join(f"- {dep}" for dep in subtask.get("dependencies", []))}
{reference_section}
---
Created by AI Task Bot
"""

                # CREATE_ISSUE mutationå®Ÿè¡Œ
                issue_result = await github.execute_query(
                    CREATE_ISSUE,
                    {
                        "repositoryId": repo_id,
                        "title": subtask["title"],
                        "body": issue_body,
                    },
                )

                issue_id = issue_result["createIssue"]["issue"]["id"]
                issue_url = issue_result["createIssue"]["issue"]["url"]

                # Projectã«è¿½åŠ 
                project_item_result = await github.execute_query(
                    ADD_TO_PROJECT, {"projectId": project_id, "contentId": issue_id}
                )

                project_item_id = project_item_result["addProjectV2ItemById"]["item"][
                    "id"
                ]

                # Sizeãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°
                if size_field:
                    from src.utils.size_converter import (
                        convert_effort_to_size,
                        get_size_option_id,
                    )

                    estimated_effort = subtask.get("estimated_effort", "M")
                    size_value = convert_effort_to_size(estimated_effort)
                    size_option_id = get_size_option_id(
                        size_field["options"], size_value
                    )

                    if size_option_id:
                        await github.execute_query(
                            UPDATE_PROJECT_FIELD,
                            {
                                "projectId": project_id,
                                "itemId": project_item_id,
                                "fieldId": size_field["id"],
                                "value": {"singleSelectOptionId": size_option_id},
                            },
                        )
                        logger.info(
                            f"   âœ“ Sizeãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¨­å®š: {estimated_effort} â†’ {size_value}"
                        )
                    else:
                        logger.warning(f"   âš ï¸ Sizeã‚ªãƒ—ã‚·ãƒ§ãƒ³ {size_value} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                created_issues.append({"title": subtask["title"], "url": issue_url})

                logger.info(f"   âœ“ Issueä½œæˆå®Œäº†: {issue_url}")

            state["created_issues"] = created_issues

            logger.info("\n" + "=" * 80)
            logger.info(f"âœ… [ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼] å…¨Issueä½œæˆå®Œäº†: {len(created_issues)} å€‹")
            logger.info("=" * 80)
            for i, issue in enumerate(created_issues, 1):
                logger.info(f"   {i}. {issue['title']}")
                logger.info(f"      {issue['url']}")

        except Exception as e:
            state["error"] = f"Issue creation failed: {str(e)}"
            logger.error(state["error"], exc_info=True)

        return state

    async def execute(
        self, task_description: str, repo_url: str, timeout_seconds: int = 300
    ) -> WorkflowState:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ

        Args:
            task_description: ã‚¿ã‚¹ã‚¯ã®èª¬æ˜
            repo_url: ãƒªãƒã‚¸ãƒˆãƒªURL
            timeout_seconds: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰

        Returns:
            WorkflowState: å®Ÿè¡Œçµæœ
        """
        initial_state = WorkflowState(
            task_description=task_description,
            repo_url=repo_url,
            repo_path=None,
            is_implemented=False,
            confidence=0.0,
            subtasks=[],
            created_issues=[],
            error="",
        )

        try:
            result = await asyncio.wait_for(
                self.workflow.ainvoke(initial_state), timeout=timeout_seconds
            )
            return result
        except asyncio.TimeoutError:
            logger.error(f"Workflow timeout after {timeout_seconds}s")
            initial_state["error"] = "Workflow timeout"
            return initial_state
