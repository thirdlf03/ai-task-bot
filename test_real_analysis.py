#!/usr/bin/env python
"""å®Ÿéš›ã®ãƒªãƒã‚¸ãƒˆãƒªåˆ†æã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""

import asyncio
from pathlib import Path
from src.repository.analyzer import RepositoryAnalyzer
from src.ai.agents.task_breaker import TaskBreakdownAgent
from src.config import settings


async def test_real_repository_analysis():
    """å®Ÿéš›ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’åˆ†æã—ã¦ã¿ã‚‹"""

    # ãƒ†ã‚¹ãƒˆã‚¿ã‚¹ã‚¯ä¾‹
    test_tasks = [
        "READMEã«ç’°å¢ƒæ§‹ç¯‰æ‰‹é †ã‚’è¿½åŠ ã™ã‚‹",
        "Discord botã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’æ”¹å–„ã™ã‚‹",
        "GitHub APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™å‡¦ç†ã‚’å®Ÿè£…ã™ã‚‹",
    ]

    print("="*80)
    print("å®Ÿéš›ã®ãƒªãƒã‚¸ãƒˆãƒªåˆ†æãƒ†ã‚¹ãƒˆ")
    print("="*80)

    for task_num, task_description in enumerate(test_tasks, 1):
        print(f"\n{'='*80}")
        print(f"ãƒ†ã‚¹ãƒˆ {task_num}: {task_description}")
        print(f"{'='*80}")

        # Step 1: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        print("\n[Step 1] ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º")
        print("-" * 40)

        try:
            breakdown_agent = TaskBreakdownAgent()
            keywords = await breakdown_agent.extract_keywords(task_description)
            print(f"âœ“ æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}")
        except Exception as e:
            print(f"âš  Gemini APIã‚¨ãƒ©ãƒ¼ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: æ‰‹å‹•ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¨­å®š
            if "README" in task_description:
                keywords = ["readme", "doc", "setup"]
            elif "Discord" in task_description:
                keywords = ["discord", "bot", "error", "command"]
            elif "GitHub" in task_description:
                keywords = ["github", "api", "rate", "limit"]
            else:
                keywords = ["config", "main"]
            print(f"âœ“ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}")

        # Step 2: ãƒªãƒã‚¸ãƒˆãƒªåˆ†æ
        print("\n[Step 2] ãƒªãƒã‚¸ãƒˆãƒªåˆ†æ")
        print("-" * 40)

        analyzer = RepositoryAnalyzer(Path("."))

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ„ãƒªãƒ¼
        file_tree = analyzer.get_file_tree(max_depth=2)
        print(f"âœ“ ãƒ•ã‚¡ã‚¤ãƒ«ãƒ„ãƒªãƒ¼å–å¾—å®Œäº† ({len(file_tree)} æ–‡å­—)")

        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼
        summary = analyzer.get_project_summary()
        print(f"âœ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚µãƒãƒªãƒ¼:")
        print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {summary['file_counts']}")
        print(f"  - ç·è¡Œæ•°: {summary['total_lines']}")
        print(f"  - ä¸»è¦è¨€èª: {summary['primary_language']}")

        # Step 3: ripgrepæ¤œç´¢
        print("\n[Step 3] ripgrepã§ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢")
        print("-" * 40)

        matched_files = analyzer.ripgrep_search(keywords)
        print(f"âœ“ ãƒãƒƒãƒã—ãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(matched_files)}")

        for i, file_path in enumerate(matched_files[:10], 1):
            print(f"  {i}. {file_path}")

        if len(matched_files) > 10:
            print(f"  ... ä»– {len(matched_files) - 10} ãƒ•ã‚¡ã‚¤ãƒ«")

        # Step 4: è³¢ã„ã‚³ãƒ¼ãƒ‰æŠ½å‡º
        print("\n[Step 4] tree-sitterã§é–¢æ•°/ã‚¯ãƒ©ã‚¹æŠ½å‡º")
        print("-" * 40)

        code_content = analyzer.read_code_intelligently(
            keywords, max_functions=10, max_chars=10000
        )

        print(f"âœ“ æŠ½å‡ºã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„:")
        print(f"  - æ–‡å­—æ•°: {len(code_content)}")
        print(f"  - è¡Œæ•°: {code_content.count(chr(10))}")

        # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        print("\n[ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®30è¡Œï¼‰]")
        print("-" * 40)
        lines = code_content.split('\n')[:30]
        for line in lines:
            print(line)

        if len(code_content.split('\n')) > 30:
            print("...")
            print(f"ï¼ˆæ®‹ã‚Š {len(code_content.split(chr(10))) - 30} è¡Œï¼‰")

        # Step 5: æœ€çµ‚çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        print("\n[Step 5] Geminiã«æ¸¡ã™æœ€çµ‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ")
        print("-" * 40)

        repo_context = f"""
# Project Structure
{file_tree}

# Project Summary
{summary}

# Related Code
{code_content if code_content else "No relevant code files found."}
"""

        print(f"âœ“ æœ€çµ‚ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:")
        print(f"  - ç·æ–‡å­—æ•°: {len(repo_context)}")
        print(f"  - ç·è¡Œæ•°: {repo_context.count(chr(10))}")

        # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®æ¦‚ç®—ï¼ˆãŠãŠã‚ˆã4æ–‡å­—=1ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
        estimated_tokens = len(repo_context) // 4
        print(f"  - æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: ~{estimated_tokens} tokens")

        # ã‚³ã‚¹ãƒˆæ¦‚ç®—ï¼ˆGemini 2.0 Flash: $0.075 / 1M input tokensï¼‰
        estimated_cost = (estimated_tokens / 1_000_000) * 0.075
        print(f"  - æ¨å®šã‚³ã‚¹ãƒˆ: ${estimated_cost:.6f} (input only)")

        # æ¯”è¼ƒ: æ—§æ–¹å¼ã§ã®æ¨å®š
        print("\n[æ¯”è¼ƒ] æ—§æ–¹å¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“èª­ã¿è¾¼ã¿ï¼‰ã¨ã®é•ã„")
        print("-" * 40)

        # æ—§æ–¹å¼ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        old_total_chars = 0
        for file_path in matched_files[:10]:
            if file_path.suffix == ".py":
                try:
                    old_total_chars += len(file_path.read_text())
                except:
                    pass

        old_estimated_tokens = old_total_chars // 4
        old_estimated_cost = (old_estimated_tokens / 1_000_000) * 0.075

        print(f"  æ—§æ–¹å¼:")
        print(f"    - æ–‡å­—æ•°: {old_total_chars}")
        print(f"    - æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³: ~{old_estimated_tokens} tokens")
        print(f"    - æ¨å®šã‚³ã‚¹ãƒˆ: ${old_estimated_cost:.6f}")

        print(f"  æ–°æ–¹å¼:")
        print(f"    - æ–‡å­—æ•°: {len(code_content)}")
        print(f"    - æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³: ~{estimated_tokens} tokens")
        print(f"    - æ¨å®šã‚³ã‚¹ãƒˆ: ${estimated_cost:.6f}")

        if old_total_chars > 0:
            reduction = ((old_total_chars - len(code_content)) / old_total_chars) * 100
            print(f"  ğŸ’° å‰Šæ¸›ç‡: {reduction:.1f}%")
        else:
            print(f"  ğŸ’° å‰Šæ¸›ç‡: N/A")

        print("\n" + "="*80)
        print("æ¬¡ã®ãƒ†ã‚¹ãƒˆã¾ã§2ç§’å¾…æ©Ÿ...")
        print("="*80)
        await asyncio.sleep(2)

    print("\n" + "="*80)
    print("âœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("="*80)


if __name__ == "__main__":
    asyncio.run(test_real_repository_analysis())
